ğŸ”¹ Approaches to Solve Word Frequency
1. Streams + Collectors.groupingBy (Your Approach) âœ…

Best balance of readability + power.

import java.util.*;
import java.util.stream.*;

public class WordFrequencyStream {
    public static void main(String[] args) {
        List<String> words = Arrays.asList("apple", "Banana", "Orange", "banana", "apple");

        Map<String, Long> wordFrequency = words.stream()
                .collect(Collectors.groupingBy(
                        word -> word.toLowerCase(),  // normalize case
                        Collectors.counting()));     // count occurrences

        System.out.println("Word Frequency: " + wordFrequency);
    }
}


âœ… Time: O(n)
âœ… Space: O(n)
âœ… Concise, expressive, modern Java
ğŸ’¡ Best for interviews

2. Using Map.merge() (Imperative, More Control)

Sometimes interviewer asks without Streams (to test Map APIs).

import java.util.*;

public class WordFrequencyMerge {
    public static void main(String[] args) {
        List<String> words = Arrays.asList("apple", "Banana", "Orange", "banana", "apple");

        Map<String, Integer> wordFrequency = new HashMap<>();
        for (String word : words) {
            wordFrequency.merge(word.toLowerCase(), 1, Integer::sum);
        }

        System.out.println("Word Frequency: " + wordFrequency);
    }
}


âœ… Time: O(n)
âœ… Space: O(n)
âœ… Very efficient, avoids Stream overhead
ğŸ’¡ Good for performance-sensitive use cases

3. Parallel Streams (for Large Input)

For huge datasets, parallelize counting.

import java.util.*;
import java.util.stream.*;

public class WordFrequencyParallel {
    public static void main(String[] args) {
        List<String> words = Arrays.asList("apple", "Banana", "Orange", "banana", "apple");

        Map<String, Long> wordFrequency = words.parallelStream()
                .collect(Collectors.groupingByConcurrent(
                        word -> word.toLowerCase(),
                        Collectors.counting()));

        System.out.println("Word Frequency: " + wordFrequency);
    }
}


âœ… Uses groupingByConcurrent â†’ thread-safe
âœ… Parallelism helps on large data
âš ï¸ Overhead not worth it for small lists

ğŸ”¹ ğŸš€ Sr. SDET Takeaways

Small/medium input (interview demos): ğŸ‘‰ Streams + groupingBy (your solution)

Performance-critical system: ğŸ‘‰ Map.merge() (lower overhead)

Large datasets / concurrency: ğŸ‘‰ Parallel Stream + groupingByConcurrent